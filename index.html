<HTML>
    <title>programing</title>
    <BODY BGCOLOR = "blue" TEXT= "white">
        <h1><center>WHAT IS PROGRAMING,Data Structure,Computer And machines.</center></h1>
        <CENTER>
        <TABLE>
        <TR>
        <TH>DATE CREATED</TH><TH>YEAR</TH><TH>LANGUAGE</TH><TH>SOURCES</TH>
        </TR>
        <TR>
        <TD>8 JAN</TD><TD>2021</TD><TD>HTML</TD><TD>NIL</TD>
        </TR>
        </TABLE>
        </CENTER>
      
        <IMG SRC="imgres.htm"ALIGN=center>

            <UL TYPE="square"> 
                <LI>What is programing?
                <LI>What are programing Languages
                <LI>The history of programing
                <LI>Computer 
                <LI>History of computers
                <LI>elements of a Computer
        
        <h1><center>WHAT IS  a Program??</center></h1>
    <P>Programme is a sequence of instructions written in a proper language through which the computer can understand and solve the problem given to it. It is the method by which the whole computing process is directed and controlled. Preparing a programme for the computer is known as “programming”.

        A programme should be recorded on a proper medium which the computer can process. Usually punched cards are used for this purpose. Each computer can understand one language which is known as “machine language”.
        
        Machine language contains use of numeral codes and each computer has its own machine language. It is very difficult to write a programme in this language. To obliterate this difficulty, some other languages have been developed.
        
        These can be grouped into following two categories:
        
        
        
        A machine oriented language can only be used on a computer for which it has been designed. This language contains alphabetic codes, which are known as unmemoric codes. So, it is easier to remember unmemoric codes than numeric codes and it is easier to write a programme in this language.
        
        A machine oriented language is oriented to a particular computer and not oriented to a particular problem. To avoid this difficulty, problem oriented languages have been developed. It is easier to write programmes in these languages. These are also known as high level languages.
        
        These languages are also to be translated before execution. The programme used for translation in this case is known as ‘computer programme’. It is a standard programme written and supplied by the computer manufacturers for doing translation job.
        
        It is a programme which translates programme in a language other than the machine code of a specific computer into instructions which a computer can obey. Because of this, language barrier between men and computer is broken down.
    </P>
    <P>Some problem oriented languages are:

        FORTRAN (Formula Translation)
        
        ALGOL (Algorithmic Language)
        
        COBOL (Common Business Oriented Language)
    </P>
    <p>Programming is important in our daily life to enhance and increase the power of computers and the internet. Programming is important for speeding up the input and output processes in a machine. Programming is important to automate, collect, manage, calculate, analyze the processing of data and information accurately
    </p>
    <P>Programme is a sequence of instructions written in a proper language through which the computer can understand and solve the problem given to it. It is the method by which the whole computing process is directed and controlled. Preparing a programme for the computer is known as “programming”.</P>
    <P>A programming language is a formal language comprising a set of instructions that produce various kinds of output. Programming languages are used in computer programming to implement algorithms. Most programming languages consist of instructions for computers.</P>
    <P>.</P>
    <P>.</P>
    <P>Java is one of the most popular programming languages in the world. Java 1.0 was released in 1995 on the principle of 'Write Once Run Anywhere'. It is a class-based, object-oriented language which is designed to be portable which means that you can find it on all platforms, operating systems and devices.</P>
    <P>The different types of programming languages are discussed below.
        Procedural Programming Language. ...
        Functional Programming Language. ...
        Object-oriented Programming Language. ...
        Scripting Programming Language. ...
        Logic Programming Language. ...
        C++ Language. ...
        C Language. ...
        Pascal Language.</P>
        <h1><center>THE HISTORY OF CODING</center></h1>
        <P>Ford states that computers can only obey instructions that are issued to them.  In order for the instructions to be understood by both user and the computer there needs to be an interface to aid in the communication. This is where computer programming languages come in – their primary function  is to aid the communication between the computer and the user. They provide a link between the human language and the machine language.  There is a huge variety of programming languages and each language has it’s own set of strengths and weaknesses and is geared with specific applications. Even though there is a huge number of computer languages out there today, computer languages are a fairly new field, since the first high-level languages were written in the 1950’s, around the time computers were invented.  The earliest computers were programmed in binary so the set of instructions was just a series of 0 and 1. The interface back then was low-level language – when a computer is given a series of instruction via a program, the computer executes the task and the interface in which the user communicates with the computer can either be a low- level or a high-level language. A high -level language does not communicate directly to the computer. Rather, high level languages is a language with a series of abstractions. Higher level languages allow the programmer to communicate more conveniently to the computer. Programming languages, together with their compilers span the gap between low-level, or binary, instructions that helps the machine understand and the high level languages, which allows the programmer to be more expressive.</P>
        <P>In software development, the programming language must be compatible with the design methodology at the design stage of software development. A facility is viewed as consisting of tools and methodologies and these should be compatible for maximum benefits. It is necessary to examine the relationship of the programming language to other components of a software development facility – the first programming languages were designed for programming rather than for software development. However, even if a language was not designed with the goal of software production in mind, it must be evaluated on that criterion because that is the desired end.</P>

           <P> As a result, the software development process has imposed language design goals. First, reliability – users should feel comfortable in using the programming language even in the presence of infrequent of undesirable events like hardware or software failures. This is also linked to correctness – software is correct if it behaves according to its specifications – the more rigorously and unambiguously the specifications are set down, the more convincingly program correctness can be proved. Reliability consists of readability, writability in the language and the ability to deal with exceptions, or so that the system is predictable even in abnormal situation. Second, maintainability – software costs have risen and increasingly complex software systems have been developed, so economic considerations have reduced the possibility of throwing away existing software and developing similar applications from scratch. Existing software must be modified to meet new requirements. Examples of a language being modifiable is
            
            Modifiable examples are allowing constants to be given symbolic names, or just altering something in one line of the program to be changed and implemented in many other places in the program.Third, efficiency – always a goal for the execution of any software system, and affects both the programming language and the choice of algorithms to be used.Efficiency is no longer measured by the execution of speed and space. The initial effort required to produce a program and the effort required in maintenance are also components of efficiency. Language supports efficiency if it has qualities of writability, maintainability, and optimizability. Optimizability is the quality of allowing automatic program optimization. This is important because a lot of the time traditionally spent in programming is spent on trying to find an efficient way of doing things. This should be removed from the early stages of the programming. So a developer should first write a program that is demonstrably correct, then through a series of efficiency improving transformations, modify the program to obtain a correct and efficient one. Generally, features that promote optimizability hamper readability.These three goals can be achieved by appropriate tools and should be the certain characteristics of the programming language.
            
            Technically speaking, users use two sets of commands when they program on a modern computer; one for the operating system and one for the programming language. The operating system is basically a program which is loaded each time the computer is turned on and provides the set of instructions for the programmer to control operations in the computer. These operations include logging in, loading files, displaying information, and running a program. The operating system program provides the facilities to allow communication between the user and the computer to be initiated and continued.
            
            A translation program is needed to convert a programming language to translate a higher level programming language to the executable machine code so that the computer processor may understand. The two means of translating higher level languages are by compilers and interpreters. Compilers take the source code of the higher level programming language and converts it into object code (the 1s and 0s). This converts the entire program in one go and then resaves it in its converted form.  he translated object code is then linked and run. One of the advantages of using a compiler is that there are no errors in the syntax when the program is run since it would have shown up earlier at the translation stage. However, a compiler requires space to accommodate both the source and object files. On the other hand, interpreters look at the program statement by statement and translate and execute the single statement before going on to the next. This means that translation and the execution happen simultaneously, not separately as with the compiler. The main advantage of the interpreter is that it is more effective in  debugging programs. However, interpreters suffer from poor execution speeds than compilers since each line has to be translated and executed, whereas the compilers translates it all at once.
            
            Programs, on the other hand,  have been around since the first computing device.</P> The oldest artificial computing device, other than the abacus, is the Blaise Pascal/s Arithmetic Machine. Before computer programming languages were made, paper tapes and punch cards which held complicated weaving patterns for the loom Tabulating Machine Company Looms by Jacquard in 1710. A century  later, Charles Babbage starting building a computing machine and the Analytical Machine. In the 20th century, Herman Hollerith founded the Tabulating Machine a while later. His machine Tabulators were used to speed up the counting and sorting punch cards. In the early 1940’s J. Presper Eckert and John W. Mauchly started building the ENIAC (Electronic Numerical Integrator and Calculator), which was completed in 1946. Around the same time, near the end of World War II, Konrad Zuse began building his second generation electromechanical computers in Germany. After Zuse successfully completed building his computer in 1945, he realized that he had no additional equipment for repairs or any kind of hardware development. He then turned his focus from hardware toward designing programming languages. Zuse is often referred to as the “father” of today’s computer programming due to his contribution to the first programing language which was powerful enough to be able to express sophisticated programs.
            
           <P> <h1><center>HISTORY OF LANGUAGES</center></h1>
            Software development process originally consisted only of the coding phase. The computer was mainly used in the early days in scientific applications – an application was programmed by one person. The problem to be solved, like a differential equation, was well-understood. There was not much need for requirements analysis or design specification or even maintenance.
            
            The first programmable computers only “spoke” machine language, which is well known to be unreadable and tedious to work with. After, programming languages evolved to assembly languages which quickly became popular and  lot easier to work with. A disadvantage is that the assembly language is very limited since it only provides facilities already in the machine code. The assembly language gives the programmer access to the machine code instructions and the macros. The macros offers a single instruction to give a combination a combination of several machine code instructions and provide common requirements.  The introduction of assembly language in the 1950’s paved the way and provided the key to later productions of of high level computer programming languages.The machine code and the assembly language are typically known as low-level languages. Assembly language offers the programmer the advantage of being able to specify where the programmer wants to allocate where the memory and data will start. This relieves some responsibility of the programmer to keep careful control over the memory. High level languages, on the other hand, take all responsibility away from the programmer. Rather, the use of variable names allow the programmer to reference particular parts of a program. 
            
            When computers were first electronically created, the limitations from the hardware forced programmers to write programs that directly communicated with the computer’s machine code. This was the assembly language. The assembly language implemented the symbols and number representations from the machine codes. Working with assembly languages was a very tedious and inefficient task. Assemblers created object code, or a system of instructions that executed directly by the computer’s central processing unit (CPU). An advantage to writing a program in the assembly language was the that it took less time to execute since it was a direct execution from the CPU. However, there were many disadvantages of writing programs in the assembly languages. Assembly language  associated the machine-language code to symbolic representations in the human language. This was one of the reasons why, it was so tedious to program with the assembly language. A programmer needed to be highly skilled and familiar with assembly language to communicate with the assembly code. Additionally, written programs in assembly language were very prone to errors.  The assembly languages are often referred to low-level languages since it execute directly from the CPU. In order to solve this problem, a high-level programming language was created with a set of instructions more closely associated to the human language. </P>
            
            <P>FORTRAN
            
            The very first high-level programming language was FORTRAN, which stands for FORmula TRANslation , It was developed in 1956 (first manual appeared in 1956, but first developed in 1954) by John Backus, a worker at IBM. FORTRAN’s goal was to ease the pain of writing in assembly language. When FORTRAN was first introduced, it was looked on suspiciously since almost all the programmers then only worked with the machine code and assembly languages. The programmers at that time had an initial belief that programs compiled from high-level language would be less efficient than those written at low-level. In order to persuade potential users of the benefits of working with a high-level language, Backus designed an excellent compiler for FORTRAN so the programs were just as efficient as those written in low-level languages. This was the best compiler for many years.   
            
            FORTRAN soon became popular because it provided a realistic and desirable alternatives to low-level language programming for mathematical and scientific applications. This programming language was also the first to be widely used. However, one of the limitations of FORTRAN was that it was specifically oriented toward the IBM 704 machine. This is a major set-back since the language syntax contains many idiosyncrasies from the IBM 704 machine. From a pure programming language design standpoint this is a “cardinal sin” but historically, it is understandable. FORTRAN is known for its efficiency. Over the years, FORTRAN had been upgraded and developed into FORTRAN -II, FORTRAN -IV, FORTRAN -66, and FORTRAN -77. Early versions of FORTRAN largely restricted users. On the other hand, the later versions allowed more flexibility, but since it has adapted, it is not as easy to use as it should be. The development of the fast string processing makes FORTRAN more of a general-purpose language than it used to be, but it is still described as a mathematical or scientific language. </P>
            
            <P>Lisp
            
            In contrast to FORTRAN, Lisp was first developed in 1956 as a functional language for list processing. LISP is one of the most used of the old, “classical” programming languages developed in the 1950’s. The design was motivated by the need of Artificial Intelligence researchers for an appropriate language. But gradually replaced or challenged in AI applications by Prolog. There are very few language constraints in LISP.  Lists are the sole data structure and the only operations are function invocations, conditional expressions and recursion. Iteration is achieved by recursion. Lisp is one of the very few “functional” as opposed to “procedural” programming languages. A procedural language requires the user to express each step in performing an action whereas a functional language merely specifies what has been done. </P>
            
   <P> Cobol
            
            Another first generation computer program language that impacted the design of recent languages was Cobol (COmmon Business Oriented Language). Cobol was created by Grace Hopper in 1960 and was heavily supported by the U.S. government. Cobol was originally designed to be the common business language in the nation. The design of Cobol was discussed in the pentagon with 6 computer manufacturers.  This maybe why the language is still in use even though it is very wordy and lacking in logical modules – resulting in a unique English-like style that some have described as verbose. One of the advantages of  Cobol is is certain applications involving processing dollars and cents. Other advancements in Cobol include the character string data. Cobol is generally used globally in the government and military. Overall, Cobol was, and is still important because of its use for business applications.
            
            The first three high level languages mentioned – FORTRAN, LISP, and COBOL – were and still widely used, or have descendants that are widely used. These languages, with their diverse purposes, set the foundation for most of today’s programming languages.</P>
            
            BASIC
            
            Once the use of high-level languages became more widespread, programmers wanted to create  a programming language that would serve as an easy introduction to FORTRAN.  As a result, BASIC was designed by Thomas Kurtz and John Kemeny  at Dartmouth College in 1963-1964 as an easy and interactive language. However, now BASIC (Beginner’s All Purpose Symbolic Instruction Code) is the most used language on microcomputers.The main purpose was to be a simple introduction which would prepare students to use FORTRAN later. BASIC was easier to program and had a user-friendly syntax than FORTRAN. The only aspect in which FORTRAN is better than BASIC is that it FORTRAN has more advanced features. BASIC is a general purpose language.Since the earliest use of BASIC was in education, the original language was fairly primitive and had only single variable names. However, people discovered that BASIC could be used as an applications programming language.  Interestingly enough, BASIC was not very popular when it first came out. However, microcomputers adopted BASIC as the preferred language since it was an interpretive language. Also, BASIC, in new forms, is still widely used. For example, BASIC is the foundation and large influence for languages like Microsoft Visual Basic and the object-oriented language Visual Basic .NET.
            
            Algol-60 
            
            Many other programs sprang up to improve the FORTRAN language. Algol-60 was created in 1958 as an improvement of FORTRAN . Then it was then redesigned, improved, and the final report was published in 1960. The key features of Algol-60 are that the syntax and the semantics are more orthogonal and that the language syntax is defined formally. This language is one of the most ingenious language definition efforts in the early days of programming languages, but never received widespread acceptance. The main language innovations are that Algol implemented a nested block structure, where code sequences and their associated declarations could be grouped into blocks without the need to be separate, explicitly named procedures. Also, Algol featured lexical scoping – where a block can consist of private variables, procedures and functions but is invisible to code outside of the block, which is mainly information hiding. It is argued that Algol 60 is an obvious milestone to the development of programming languages because of its introduction of key concepts and its first use of formal notation for syntax. A large portion of the theoretical, practical and compiler work since Algol’s introduction has used Algol as the foundation.
            
            The main flaws, however, were the omission of IO and to a lesser degree the costly parameter passing method “By Name”. There are many improvements to the Algol-60 such as the Algo-W which was designed in the mid 1960s. Algol-W is very closely related to the Algol-60 even though they are not compatible with each other. The greatest difference between the Algol-W and the Algol-60 was that parameters no longer passes by name and that the For Statement was redesigned.
            
            The next three programming languages – Pascal, C and Prolog, developed in 1970 and 1972 respectively, are some of the key languages of the period of a boom of programming languages, though C and Prolog spawned meaningful descendant languages. Most importantly, this period was when language paradigms, or certain “styles” were created. The paradigms are object-oriented programming, imperative programming, logic programming, and functional programming, and some may add the concurrent and database paradigms. This period of programming development also spurred the great goto and structured programming debate where structured programming forced structure on the programmer in language development. However, there is a general consensus that the goto statement should not be used because it has the potential of making programs hard to read because a user will have to jump around in a program to search for all the targets of goto statements – and the existence of goto statements complicates automatic optimization.
            
            Pascal
            
            One of the largest criticisms with the early computer programming languages were that it was not portable. Languages like BASIC was non-standard in nature. BASIC programs written in one system  often had to be completely rewritten for another make of a computer. To solve this problem, Pascal was designed between 1968 and 1970 by Niklaus Wirth of Zurich. Pascal was strongly influenced by Algo-w, a close relative to Algo-60. Pascal was intended as a teaching tool for illustrating the proper design data structures and structured statements. One of the greatest advantages in Pascal is it’s “portability.” Unlike FORTRAN and BASIC, Pascal has a self-compiler which allows programs in Pascal to be moved from different systems. Additionally, Pascal was so well-suited for compiler writing that the CDC-660 compiler could translate the whole compiler in a few seconds. Pascal is also a well structured language because it allows a series of statement to be grouped together,  their programs are made to be very readable,  and they have a provision of versatile procedure and function facilities. Mayer (1988) states that Pascal is “a too good a language for the modest aim for which it was invented” (p. 10). The greatest limitations however, was that it was not designed with a specific area of application in mind. Therefore, Pascal is more of a general purpose language but lacks special features for particular application.
            
            C
            
            The programming language C was created by Dennis Ritchie in 1972. It is a general-purpose, not very high level language and  mainly used as the system’s language for the operating system UNIX. The chief design goal of C was to be a tool for working programmers, and therefore useful. C is a very popular language for the development of applications since it is flexible, convenient, powerful, efficient, and portable. Since it is a modern language, C provides the comprehensive range of control structures needed to allow well-structured programs to be written. C does not behave like a typical high level language because it offers features similar to low level languages since it is very similar to the source code. Basically, C is a systems language that features low level access with high level operators.
            
           <P> Prolog
            
            Prolog is a non-procedural language with a focus on “logic programming”. In a Prolog program, it is not only necessary to express “how” a problem is to be solved but it’s not even possible to express this. The programmer specifies only “what” has to be done and Prolog does the rest – the program requires a data base of facts or knowledge – the programmer will ask questions and Prolog responds with the list of all possible correct answers that are inferred from the data base of facts. Prolog’s clauses for establishing the data base can be executed in any order – they can be run in parallel. As a result, Pascal became a natural candidate as the systems language on the Japanese fifth generation supercomputers, or “inference engines” because Pascal achieves considerable speed even though a typical, single Prolog operation consumes a lot of processor time. In general, Pascal’s main use was for general and educational purpose and supported structured programming.</P>
           
            The next two programs, in particular Ada, reflect the period of language design where scaling up to large systems was big with the use of modules – which also increased the use of generics, or generic programming constructs, which are parameterized modules. Also, the reduced instruction set computer (RISC) movement gave rise gearing hardware design from assembly programmers and for compilers – resulting in more focus in compilation technology for high level programming languages.
            
            Ada
            
            In the 1980’s additional computer program languages were created to match with the speed and efficiency advancement of the computer. In 1983  after almost a decade of careful study of previous errors in programming language design – promising Ada introduced. Ada was expected by some in the computer science field to be the first language with the potential of becoming the universal, almost exclusive language of the future for embedded systems. The focus of the design of Ada was driven by the U.S. Department of Defense, who wanted a program that would reduce the number of military standard languages. Ada had the unique advantage of having been defined as an American National Standard before any implementation became available, saving it from a proliferation of corrupted language versions.  Ada incorporates Pascal’s best ideas and corrected errors and omissions and has a much wider range of applications than Pascal – also Ada is “strongly typed”. Ada’s problems are that IO is not defined as part of the language etc. In general, Ada’s intended purpose was to be a general purpose, real-time language with embedded applications.
            
            C ++
            
            Another computer program language that object-oriented and systems programming designed int he 1980s is C++. C++ was unique in that it tried to mix in the high-level language features with low-level language features, making it a medium-level language. C++ was created by Bjarne Stroustrup in 1979 originally as C with Classes. In 1983, the name was changed to C ++. C++ is one of the most popular languages ever created and is widely used in the software industry. C++ is based off of C and it even compatible with C. The improvements of C++ from C is the addition of classes, exception handling, virtual functions, operator overloading, user-controlled free-store memory control, and improved type checking. Stroustrup designed C ++ as the ideal program to work with software. When Stroustrup was working in Software Development, he found that the program Simula had very useful features, but the program was too slow to use. Heavily influenced by Simula, he based his improvements of C on features in Simula and combined it with the speed and efficiency of C. However, there are some major criticisms of C++. Critics argue that C++ is too complicated. The language definition document of C ++ is almost three times as long as the language definition of C. Other drawbacks of C++ are that there are no features that create multi-threaded software and lacks a garbage collection.
            
            JAVA
            
            <P>JAVA was created to simplify C ++ and was created due to the rise of the Web. JAVA was developed by James Gosling in 1991, and released in 1995. JAVA ‘s syntax is heavily derived from C ++, but has a much simpler object model and has less low-level facilities.   The five goals of JAVA are:
            
            1) Simple, object oriented, and familiar
            
            2) Secure
            
            3) Architecture neutral and portable
            
            4) High performance
            
            5) Interpreted, threaded, and dynamic. </P>
            
            In contrast to C ++, JAVA is object-oriented, platform-independent, multi-threaded.  JAVA is used as a foundation of Web, network services, applications, and many embedded devices in addition to the programming language HTML. Another feature of JAVA is that it allows programmers to write software on one platform, also know as the hardware architecture, and run it on another platform. Overall, JAVA meets most its goals, it is familiar since it is closely related to C++ and it’s platform allows for JAVA’s programs to be portable. It has features that are lacking in C ++ such as an automatic garbage collector to manage the Internet. One of the major drawbacks of JAVA, however, is that its run time is a bit slow. Also, the majority of JAVA is opened sourced. JAVA is one of the many new languages that appeared in the 1990s in response to the boom of the Internet. All the developed languages of this time were object-oriented languages. Other languages introduced at this time were PHP and Python.
            <P>.</P>
            <P>.</P>
            <P>.</P>
            <P>.</P>
            <P>Wikipedia claims there are approximately 700 programming languages, while others say that number is closer to 9000! The truth is, there've been countless programming languages created throughout history. But like spoken languages, there's a hierarchy of programming languages based on their prevalence and usage</P>
           <P>.</P>
           <P>.</P>
            <P> Convergence – some languages may reach a dead end. The evolution of languages is convergence – the space of possibilities is smaller and partly because mutations are not random – language designers deliberately incorporate ideas from other languages.</P>
           <P>.</P>
           <P>.</P>
           <P>.</P>
           <P>What is Computer Basic language?</P>
           <P>Stands for "Beginner's All-purpose Symbolic Instruction Code." BASIC is a computer programming language that was developed in the mid-1960s to provide a way for students to write simple computer programs.</P>
           <P>.</P>
           Being a good programmer isn't impossible - whether you choose to get a CS degree, take up a couple of online coding courses, attend a coding bootcamp or even teach yourself how to code. Remember that there are no hard and fast rules when it comes to learning how to code.
           <P>.</P>
           <P>Now,lets discuss about the editors where codes can be written-</P>
           <P>.</P>
           <P>Physically, on my computer, where can I code? To write a program in any language you simply need a plain text editor (such as Notepad if you're on Windows. It's not very pleasant, though, because it's not really designed to code. It's better to download a text editor like Notepad++ or Sublime</P>
           <h1><center>FINDING A JOB AS A PROGGRAMER</center></h1>
           <P>Definitely as far as rewarding, working with people solving difficult problems. Programming is a career that is a lot more interesting than a lot of alternatives out. ... A software development career is very high paying career. You can make a lot of money, you can get right out of high school, and make a six figure job.how hard is it to get a job programming? Since there is a global labor shortage in the field, it is not that hard. ... Although most companies do not measure your coding skills in certificates but rather give you some coding tests or real tasks. If you can code, you will get a job.Programming and Coding jobs are not dying, just the types of developers being hired is changing. Bootcamps closing has more to do with their business model and the willingness of company to hire their graduates than it does with the job market.Despite popular myths, you can become a software developer without a college degree. Whether you're re-entering the workforce or stuck in a career you dislike (administration, operations, banking, etc.), becoming a software developer is totally within your grasp—as long as you're willing to put in the hard work</P>
           <h1><center>Now,let us have a look at the importance of proggraming-</center></h1> 
           <UL TYPE="square">
           <LI>Programming is important in our daily life to enhance and increase the power of computers and the internet. Programming is important for speeding up the input and output processes in a machine. Programming is important to automate, collect, manage, calculate, analyze the processing of data and information accurately.
           <LI>Programming is crucial when it comes to learning how to innovate, create very eco-friendly solutions for global problems and such. In essence, it helps in speeding up the input and output processes in a machine. ... Some of the more reasons why programming is important are: The interaction with machines and computers
           <LI>Studying programming languages will help you be better at your job, make more money, and be a happier, more fulfilled and more informed citizen, because you'll learn to: Choose the most appropriate language for a given task. A programming language lets you express computational tasks in certain ways.
           <LI>The primary purpose of programming (in a typical organization) is to communicate an algorithm to another human being (and/or a future instance of oneself). The secondary purpose is to communicate an algorithm to a machine (computer). ... The purpose of programming is to make a computer do something.
           </UL>

           <h1><center>DATA STRUCTURE</center></h1>
           <P> data structure is a particular way of organizing data in a computer so that it can be used effectively. For example, we can store a list of items having the same data-type using the array data structure. This page contains detailed tutorials on different data structures (DS) with topic-wise problems.In computer science, a data structure is a data organization, management, and storage format that enables efficient access and modification. More precisely, a data structure is a collection of data values, the relationships among them, and the functions or operations that can be applied to the data.Data Structures (DS) tutorial provides basic and advanced concepts of Data Structure. Our Data Structure tutorial is designed for beginners and professionals.

            Data Structure is a way to store and organize data so that it can be used efficiently.
            
            Our Data Structure tutorial includes all topics of Data Structure such as Array, Pointer, Structure, Linked List, Stack, Queue, Graph, Searching, Sorting, Programs, etc.
            
            
            What is Data Structure?
            The data structure name indicates itself that organizing the data in memory. There are many ways of organizing the data in the memory as we have already seen one of the data structures, i.e., array in C language. Array is a collection of memory elements in which data is stored sequentially, i.e., one after another. In other words, we can say that array stores the elements in a continuous manner. This organization of data is done with the help of an array of data structures. There are also other ways to organize the data in memory. Let's see the different types of data structures.
            
            The data structure is not any programming language like C, C++, java, etc. It is a set of algorithms that we can use in any programming language to structure the data in the memory.
            
            To structure the data in memory, 'n' number of algorithms were proposed, and all these algorithms are known as Abstract data types. These abstract data types are the set of rules.
            
            A data structure is a way of organizing the data so that it can be used efficiently. Here, we have used the word efficiently, which in terms of both the space and time. For example, a stack is an ADT (Abstract data type) which uses either arrays or linked list data structure for the implementation. Therefore, we conclude that we require some data structure to implement a particular ADT.

            An ADT tells what is to be done and data structure tells how it is to be done. In other words, we can say that ADT gives us the blueprint while data structure provides the implementation part. Now the question arises: how can one get to know which data structure to be used for a particular ADT?.
            
            As the different data structures can be implemented in a particular ADT, but the different implementations are compared for time and space. For example, the Stack ADT can be implemented by both Arrays and linked list. Suppose the array is providing time efficiency while the linked list is providing space efficiency, so the one which is the best suited for the current user's requirements will be selected. </P>

           
            Data type is a way to classify various types of data such as integer, string, etc. which determines the values that can be used with the corresponding type of data, the type of operations that can be performed on the corresponding type of data<p>*do follow teh20 *
   
                Those data types which are implementation independent as they can be implemented in one or the other way are known as derived data types. These data types are normally built by the combination of primary or built-in data types and associated operations on them
               
               
                The data in the data structures are processed by certain operations. The particular data structure chosen largely depends on the frequency of the operation that needs to be performed on the data structure.
               

                <h1><center>WHAT IS A COMPUTER???</center></h1>
                <p>The modern-day computer has become an important part of our daily life. Also, their usage has increased much fold during the last decade. Nowadays, they use the computer in every office whether private or government. Mankind is using computers for over many decades now. Also, they are used in many fields like agriculture, designing, machinery making, defense and many more. Above all, they have revolutionized the whole world.</p>
                <p>The computer runs on a three-step cycle namely input, process, and output. Also, the computer follows this cycle in every process it was asked to do. In simple words, the process can be explained in this way. The data which we feed into the computer is input, the work CPU do is process and the result which the computer give is output.</p>
                <p>The simple computer basically consists of CPU, monitor, mouse, and keyboard. Also, there are hundreds of other computer parts that can be attached to it. These other parts include a printer, laser pen, scanner, etc.

                   
                    The computer is categorized into many different types like supercomputers, mainframes, personal computers (desktop), PDAs, laptop, etc. The mobile phone is also a type of computer because it fulfills all the criteria of being a computer.</p>
                <p>As the usage of computer increased it became a necessity for almost every field to use computers for their operations. Also, they have made working and sorting things easier. </p>
                <p>The computer is a very important machine that has become a useful part of our life. Also, the computers have twin-faces on one side it’s a boon and on the other side, it’s a bane. Its uses completely depend upon you. Apart from that, a day in the future will come when human civilization won’t be able to survive without computers as we depend on them too much. Till now it is a great discovery of mankind that has helped in saving thousands and millions of lives.</p>
                <p>Today’s generation could never ever imagine in their wildest dreams about the world, ages before, when there were no computers or any other technologies. So much we have advanced that now every information is just a click away and is in your hands 24/7. All this advancement was possible only with the introduction of a small device called the “Computer”.</p>
                <p>Basically, computer is a device that accepts the message by the imputer and processes this message and stores the information at the storage devices and later gives an output of the message through the output devices.

                    A simple explanation of the computer. Normally, a computer consists of a processing unit called the Central Processing Unit or the CPU and a form of memory. In the years between 1940 and 1945 were the first electronic digital computers developed. The initial sizes were as big as a room and consumed power as much as today’s personal computers.
                    
                    Initially, computer was related to a person who carries out calculations or computations and as such the word computer was evolved in 1613 and continued till the end of 19th century. Later it as re-described as a machine that carries computations.</p>
                    <p>The early computers were limited in their functions. It was the fusion of automatic calculation and programmability that produced the first computers that were recognized in 1837. Charles Babbage in 1837 was the first to introduce and design a fully programmed mechanical computer, his analytical engine. Due to limited finances and inability of resisting tinkering with the design, he could not complete his work and it was later completed by his son Henry Babbage who made it into a simplified version of the analytical engine’s computing unit.

                        The original objective of inventing a computer was to create a fast calculating machine. During the World War II, it became very essential to understand and locate the direction and speed of the enemy weapons. Calculations had to be done accurately and mathematically and without an advanced machine it would not be possible. To defend the enemy , the front line soldiers required firing tables and only a computer could produce such firing tables with speed and accuracy at that time.
                        
                        To produce the technology then, high sums of money and brain power was required. The first computer was produced by the Moore School of Engineering called the ENIAC, on behalf of the US Army which was in 1946. The ENIAC was able to produce the firing tables, by carrying out large number of calculations accurately.
                        
                        Over a period of time computers have evolved and toady with the Artificial Intelligence technology, we use the most advanced kind of computers that have helped man in every sectors of life. At every generations of the computers or in fact during the evolution, each time computers are being launched that are lighter, smaller, speedier and more powerful. The computers have been a dominating factor since the 1970`s and today it has conquered almost all walks of life.</p>
                        <p>Computers are being used for various purposes today like weather forecasting, machinery operations, guidance of spacecraft and technology. Apart from these in the medical sector, it provides a great helping hand in storing information that could be referred later, in space technology, automation in banks, ticket booking through the net, traffic control, and even games could be played in computers on and many more. All these are possible only because of the characteristics that a computer posses like speedy, accuracy, reliability and integrity. It could executive over a billion instructions per second without committing any mistakes is completely reliable. The memory of the computer is so vast that it could hold in a large amount of data.

                            To run a computer, it is the programming that decides and it should be run in a computer. Programming is defined as a set of instructions allotted to the computer that accepts it in order to solve a problem. There are many different languages that are being used to program a computer. Some of the languages are BASIC, COBOL, C, C++, JAVA are a few to name.
                            
                            With the introduction of computers, attaining information has become a lot more easier. Computers have become the backbone of Information Technology and a major application in this sector is the Internet. With the Internet, nothing is impossible today. Apart from acquiring information, one could stay connected to friends and family, a great platform for business expansions, purchasing, studying and the list just goes on, it is endless.
                            
                            Computerization in almost all sectors, have created job opening for thousands. Computer education has been introduced at school levels and in primary classes, as such is the importance of acquiring the knowledge of computers. Every year there are thousands of students step out from universities and colleges across the globe into the world of computer technology and this youth is what is tomorrow’s assets in getting technology into the next level of advancement.</p>
                            <p>The computer has proved in all roles that it has been assigned. A great helping hand, in every sector that has been applied with computers. Telecommunication and satellite imagery are also computer based, which is added to the long list of applications computer holds in other fields.

                                With every positive, there is a negative and the same is applicable with computers also. With all the positives that one could acquire and seize, the negative side is also large. The increase in Cyber crime, pornographic websites, false identity leading to trapping of youngsters and many more. Yet , the advantages are more outnumbered and there are many preventive measures also introduced to stop the negative aspects.
                                
                                The world would not have been what it is today, had there not been an entry to this great machine even though in the crude form, ages before us. Computer has a great future and we just have to keep a watch and mark the changes coming to it.</p>
                                <h1><center>HISTORY OF COMPUTERS</center></h1>
                                <p>The first substantial computer was the giant ENIAC machine by John W. Mauchly and J. Presper Eckert at the University of Pennsylvania. ENIAC (Electrical Numerical Integrator and Calculator) used a word of 10 decimal digits instead of binary ones like previous automated calculators/computers. ENIAC was also the first machine to use more than 2,000 vacuum tubes, using nearly 18,000 vacuum tubes. Storage of all those vacuum tubes and the machinery required to keep the cool took up over 167 square meters (1800 square feet) of floor space. Nonetheless, it had punched-card input and output and arithmetically had 1 multiplier, 1 divider-square rooter, and 20 adders employing decimal "ring counters," which served as adders and also as quick-access (0.0002 seconds) read-write register storage.

                                    The executable instructions composing a program were embodied in the separate units of ENIAC, which were plugged together to form a route through the machine for the flow of computations. These connections had to be redone for each different problem, together with presetting function tables and switches. This "wire-your-own" instruction technique was inconvenient, and only with some license could ENIAC be considered programmable; it was, however, efficient in handling the particular programs for which it had been designed. ENIAC is generally acknowledged to be the first successful high-speed electronic digital computer (EDC) and was productively used from 1946 to 1955. A controversy developed in 1971, however, over the patentability of ENIAC's basic digital concepts, the claim being made that another U.S. physicist, John V. Atanasoff, had already used the same ideas in a simpler vacuum-tube device he built in the 1930s while at Iowa State College. In 1973, the court found in favor of the company using Atanasoff claim and Atanasoff received the acclaim he rightly deserved.</p>
                                    <p>In the 1950's two devices would be invented that would improve the computer field and set in motion the beginning of the computer revolution. The first of these two devices was the transistor. Invented in 1947 by William Shockley, John Bardeen, and Walter Brattain of Bell Labs, the transistor was fated to oust the days of vacuum tubes in computers, radios, and other electronics.

                                        Vaccum Tubes-
                                        The vacuum tube, used up to this time in almost all the computers and calculating machines, had been invented by American physicist Lee De Forest in 1906. The vacuum tube, which is about the size of a human thumb, worked by using large amounts of electricity to heat a filament inside the tube until it was cherry red. One result of heating this filament up was the release of electrons into the tube, which could be controlled by other elements within the tube. De Forest's original device was a triode, which could control the flow of electrons to a positively charged plate inside the tube. A zero could then be represented by the absence of an electron current to the plate; the presence of a small but detectable current to the plate represented a one.
                                        
                                        
                                        Transistors-
                                        Vacuum tubes were highly inefficient, required a great deal of space, and needed to be replaced often. Computers of the 1940s and 50s had 18,000 tubes in them and housing all these tubes and cooling the rooms from the heat produced by 18,000 tubes was not cheap. The transistor promised to solve all of these problems and it did so. Transistors, however, had their problems too. The main problem was that transistors, like other electronic components, needed to be soldered together. As a result, the more complex the circuits became, the more complicated and numerous the connections between the individual transistors and the likelihood of faulty wiring increased.
                                        
                                        In 1958, this problem too was solved by Jack St. Clair Kilby of Texas Instruments. He manufactured the first integrated circuit or chip. A chip is really a collection of tiny transistors which are connected together when the transistor is manufactured. Thus, the need for soldering together large numbers of transistors was practically nullified; now only connections were needed to other electronic components. In addition to saving space, the speed of the machine was now increased since there was a diminished distance that the electrons had to follow.</p>
                                        <p>The 1960s saw large mainframe computers become much more common in large industries and with the US military and space program. IBM became the unquestioned market leader in selling these large, expensive, error-prone, and very hard to use machines.
                                            A veritable explosion of personal computers occurred in the early 1970s, starting with Steve Jobs and Steve Wozniak exhibiting the first Apple II at the First West Coast Computer Faire in San Francisco. The Apple II boasted built-in BASIC programming language, color graphics, and a 4100 character memory for only $1298. Programs and data could be stored on an everyday audio-cassette recorder. Before the end of the fair, Wozniak and Jobs had secured 300 orders for the Apple II and from there Apple just took off.
                                            
                                            Also introduced in 1977 was the TRS-80. This was a home computer manufactured by Tandy Radio Shack. In its second incarnation, the TRS-80 Model II, came complete with a 64,000 character memory and a disk drive to store programs and data on. At this time, only Apple and TRS had machines with disk drives. With the introduction of the disk drive, personal computer applications took off as a floppy disk was a most convenient publishing medium for distribution of software.
                                            
                                            IBM, which up to this time had been producing mainframes and minicomputers for medium to large-sized businesses, decided that it had to get into the act and started working on the Acorn, which would later be called the IBM PC. The PC was the first computer designed for the home market which would feature modular design so that pieces could easily be added to the architecture. Most of the components, surprisingly, came from outside of IBM, since building it with IBM parts would have cost too much for the home computer market. When it was introduced, the PC came with a 16,000 character memory, keyboard from an IBM electric typewriter, and a connection for tape cassette player for $1265.
                                            
                                            By 1984, Apple and IBM had come out with new models. Apple released the first generation Macintosh, which was the first computer to come with a graphical user interface(GUI) and a mouse. The GUI made the machine much more attractive to home computer users because it was easy to use. Sales of the Macintosh soared like nothing ever seen before. IBM was hot on Apple's tail and released the 286-AT, which with applications like Lotus 1-2-3, a spreadsheet, and Microsoft Word, quickly became the favourite of business concerns.
                                            
                                            That brings us up to about ten years ago. Now people have their own personal graphics workstations and powerful home computers. The average computer a person might have in their home is more powerful by several orders of magnitude than a machine like ENIAC. The computer revolution has been the fastest growing technology in man's history.</p>
                                            <h1><center>PARTS OF A COMPUTER</center></h1>
                                            <p>The computer case is the metal and plastic box that contains the main components of the computer, including the motherboard, central processing unit (CPU), and power supply. The front of the case usually has an On/Off button and one or more optical drives.

                                                Computer cases come in different shapes and sizes. A desktop case lies flat on a desk, and the monitor usually sits on top of it. A tower case is tall and sits next to the monitor or on the floor. All-in-one computers come with the internal components built into the monitor, which eliminates the need for a separate case.</p>
                                                The monitor works with a video card, located inside the computer case, to display images and text on the screen. Most monitors have control buttons that allow you to change your monitor's display settings, and some monitors also have built-in speakers.

Newer monitors usually have LCD (liquid crystal display) or LED (light-emitting diode) displays. These can be made very thin, and they are often called flat-panel displays. Older monitors use CRT (cathode ray tube) displays. CRT monitors are much larger and heavier, and they take up more desk space.
The mouse is another important tool for communicating with computers. Commonly known as a pointing device, it lets you point to objects on the screen, click on them, and move them.
There are two main mouse types: optical and mechanical. The optical mouse uses an electronic eye to detect movement and is easier to clean. The mechanical mouse uses a rolling ball to detect movement and requires regular cleaning to work properly.
<h1><center>WHAT IS HARDWARE?</center></h1>
<P>Computer hardware includes the physical parts of a computer, such as the case, central processing unit (CPU), monitor, mouse, keyboard, computer data storage, graphics card, sound card, speakers and motherboard. By contrast, software is the set of instructions that can be stored and run by hardware.Computer hardware refers to the physical parts of a computer and related devices. Internal hardware devices include motherboards, hard drives, and RAM. External hardware devices include monitors, keyboards, mice, printers, and scanners.

    The internal hardware parts of a computer are often referred to as components, while external hardware devices are usually called peripherals. Together, they all fall under the category of computer hardware. Software, on the other hand, consists of the programs and applications that run on computers. Because software runs on computer hardware, software programs often have system requirements that list the minimum hardware required for the software to runAbbreviated as HW, hardware is best described as any physical component of a computer system that contains a circuit board, ICs, or other electronics. A perfect example of hardware is the screen on which you are viewing this page. Whether it be a monitor, tablet, or smartphone, it is hardware.

    Without any hardware, your computer would not exist, and software could not be used. The picture is a Logitech webcam, an example of an external hardware peripheral. This hardware device allows users to take videos or pictures, and transmit them over the Internet.
    
    </P>
    <h1><center>WHAT IS SOFTWARE?</center></h1>
    <P>Software, instructions that tell a computer what to do. Software comprises the entire set of programs, procedures, and routines associated with the operation of a computer system. The term was coined to differentiate these instructions from hardware—i.e., the physical components of a computer system. A set of instructions that directs a computer’s hardware to perform a task is called a program, or software program.The two main types of software are system software and application software. System software controls a computer’s internal functioning, chiefly through an operating system, and also controls such peripherals as monitors, printers, and storage devices. Application software, by contrast, directs the computer to execute commands given by the user and may be said to include any program that processes data for a user. Application software thus includes word processors, spreadsheets, database management, inventory and payroll programs, and many other “applications.” A third software category is that of network software, which coordinates communication between the computers linked in a network.

        Software is typically stored on an external long-term memory device, such as a hard drive or magnetic diskette. When the program is in use, the computer reads it from the storage device and temporarily places the instructions in random access memory (RAM). The process of storing and then performing the instructions is called “running,” or “executing,” a program. By contrast, software programs and procedures that are permanently stored in a computer’s memory using a read-only (ROM) technology are called firmware, or “hard software.”
        
        </P>
        <P>Software is a set of instructions, data or programs used to operate computers and execute specific tasks. ... Examples of applications include office suites, database programs, web browsers, word processors, software development tools, image editors and communication platforms.</P>
        <h1><center>OS?</center></h1>
        <P>An Operating System (OS) is an interface between a computer user and computer hardware. An operating system is a software which performs all the basic tasks like file management, memory management, process management, handling input and output, and controlling peripheral devices such as disk drives and printers.

            Some popular Operating Systems include Linux Operating System, Windows Operating System, VMS, OS/400, AIX, z/OS, etc.An Operating System (OS) is a software that acts as an interface between computer hardware components and the user. Every computer system must have at least one operating system to run other programs. Applications like Browsers, MS Office, Notepad Games, etc., need some environment to run and perform its tasks.

            The OS helps you to communicate with the computer without knowing how to speak the computer's language. It is not possible for the user to use any computer or mobile device without having an operating system.Operating systems were first developed in the late 1950s to manage tape storage
            The General Motors Research Lab implemented the first OS in the early 1950s for their IBM 701
            In the mid-1960s, operating systems started to use disks
            In the late 1960s, the first version of the Unix OS was developed
            The first OS built by Microsoft was DOS. It was built in 1981 by purchasing the 86-DOS software from a Seattle company
            The present-day popular OS Windows first came to existence in 1985 when a GUI was created and paired with MS-DOS.Some computer processes are very lengthy and time-consuming. To speed the same process, a job with a similar type of needs are batched together and run as a group.

            The user of a batch operating system never directly interacts with the computer. In this type of OS, every user prepares his or her job on an offline device like a punch card and submit it to the computer operator</P>
            <h1><center>HOW ARE COMPUTERS MADE</center></h1>
            <P>Our contemporary world is digital; the numbers back up that statement. Smartphones sell at a clip of nearly 150 million per business quarter; PCs hang in at around 100 million. And tablet computers? The sales numbers of those devices are red-hot, too, at nearly 120 million per year and counting.

                That's a heaping mountain of digital technology, spread all across the world. Yet hardly anyone knows how these machines are made. The process is in some ways rather simple and in others, bewilderingly complexParts are paramount. If you've ever so much as glimpsed into the dark innards of your desktop computer, you know that the nooks and crannies inside are stuffed with all sorts of shiny (or dust bunny-choked) components. In short, your computer is composed of a lot of individual parts.

                You're probably already familiar with the most vital ingredients that make up a typical computer recipe. You need a CPU (central processing unit), which is the so-called brain of the computer. It processes instructions given to it by software, such as your word processing or accounting programs.
                
                A computer also needs a place to store data. That's usually a magnetic hard drive. Contemporary hard drives can store many gigabytes or even terabytes worth of data. Newer (and usually more expensive) hard drives are solid-state drives that have no moving parts, and thus, aren't as susceptible to mechanical failure as older versions.
                
                Small devices, such as smartphones, often don't require as much storage capacity as full-size computers, so they employ flash memory chips like those used in digital cameras. You can swap flash cards in and out of a device for easy data sharing.
                
                Hard drives are for semi-permanent or long-term data storage. RAM (random access memory), however, is short-term storage with smaller capacity. RAM is much faster to access than a hard drive, so it's important for overall system speed and multi-tasking.
                
                A motherboard is often likened to the human central nervous system. It connects all parts and helps them function as a single machine. Without this crucial circuit board, your computer would be non-functioning collection of pricey electronics.
                
                Each of these components requires careful engineering and design, not to mention specializing manufacturing machines and expert oversight. That's why computer manufacturers can't build every part from scratch. Instead, they generally buy say, motherboards, directly from a motherboard maker, and then mix and match components to build a whole machine.
                
                We're getting a little ahead of ourselves here, though. On the next page we'll step back and see exactly where computer parts really find their beginnings.</P>
                